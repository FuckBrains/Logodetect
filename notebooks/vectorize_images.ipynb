{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as nn_F\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.transforms import functional as tran_F\n",
    "\n",
    "from logos_recognition.utils import save_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logos_path = os.path.join(os.environ['DATASETS'], 'logos', 'logos', 'all_crops')\n",
    "exemplars_path = os.path.join(os.environ['DATASETS'], 'logos', 'exemplars')\n",
    "logos_128_path = os.path.join(os.environ['DATASETS'], 'logos', 'logos', 'all_crops_128x128')\n",
    "exemplars_128_path = os.path.join(os.environ['DATASETS'], 'logos', 'exemplars_128x128')\n",
    "\n",
    "activation_layer = 'avgpool'\n",
    "device = 'cuda:1'\n",
    "model_out = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and hook model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_activation(model, activation_dic, activation_layer):\n",
    "    model.avgpool.register_forward_hook(save_activation(activation_dic, activation_layer))\n",
    "\n",
    "def save_activation(activation_dic, activation_layer):\n",
    "    def hook(model, input, output):\n",
    "        activation_dic[activation_layer] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dic = {}\n",
    "model = resnet34(pretrained=True).eval().to(device)\n",
    "hook_activation(model, activation_dic, activation_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_tensor(image):\n",
    "    return tran_F.to_tensor(image).unsqueeze(0).to(device, dtype=torch.float)\n",
    "\n",
    "def get_activation(activation_dic, activation_layer):\n",
    "    act_vec = nn_F.normalize(activation_dic[activation_layer], p=2, dim=1)\n",
    "    return act_vec.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00010183, 0.        , 0.00026326], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(0, 255, (64, 48, 3))\n",
    "model(img_to_tensor(x))\n",
    "activation = get_activation(activation_dic, activation_layer)\n",
    "\n",
    "print(np.shape(activation.squeeze()))\n",
    "activation[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_images(path, model_out, model, activation_dic, activation_layer, resize=False):\n",
    "    # Extract vectors:\n",
    "    filenames = glob.glob(path + '/*.jpg')\n",
    "    vectors = np.zeros((len(filenames), model_out))\n",
    "    for idx, img_path in enumerate(tqdm(filenames)):\n",
    "        \n",
    "        # Load image:\n",
    "        if resize:\n",
    "            image = Image.open(img_path).convert('RGB').resize((128, 128))\n",
    "        else:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "        # Vectorize image:        \n",
    "        model(img_to_tensor(image))\n",
    "        vectors[idx, :] = get_activation(activation_dic, activation_layer)\n",
    "        \n",
    "    return vectors, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76017/76017 [10:01<00:00, 126.28it/s]\n"
     ]
    }
   ],
   "source": [
    "logos_vectors, logos_filenames = vectorize_images(\n",
    "    logos_path, model_out, model, activation_dic, activation_layer)\n",
    "save_df(logos_vectors, logos_filenames, logos_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process logos (128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76017/76017 [09:46<00:00, 129.61it/s]\n"
     ]
    }
   ],
   "source": [
    "logos_128_vectors, logos_128_filenames = vectorize_images(\n",
    "    logos_128_path, model_out, model, activation_dic, activation_layer, resize=True)\n",
    "save_df(logos_128_vectors, logos_128_filenames, logos_128_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:04<00:00, 83.82it/s] \n"
     ]
    }
   ],
   "source": [
    "exemplars_vectors, exemplars_filenames = vectorize_images(\n",
    "    exemplars_path, model_out, model, activation_dic, activation_layer)\n",
    "save_df(exemplars_vectors, exemplars_filenames, exemplars_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process exemplars (128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:02<00:00, 126.02it/s]\n"
     ]
    }
   ],
   "source": [
    "exemplars_128_vectors, exemplars_128_filenames = vectorize_images(\n",
    "    exemplars_128_path, model_out, model, activation_dic, activation_layer, resize=True)\n",
    "save_df(exemplars_128_vectors, exemplars_128_filenames, exemplars_128_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
