{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as nn_F\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.transforms import functional as tran_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logos_path = os.path.join(os.environ['DATASETS'], 'logos', 'logos', 'all_crops')\n",
    "logos_128_path = os.path.join(os.environ['DATASETS'], 'logos', 'logos', 'all_crops_128x128')\n",
    "exemplars_path = os.path.join(os.environ['DATASETS'], 'logos', 'exemplars')\n",
    "exemplars_128_path = os.path.join(os.environ['DATASETS'], 'logos', 'exemplars_128x128')\n",
    "\n",
    "activation_layer = 'avgpool'\n",
    "device = 'cuda:1'\n",
    "model_out = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and hook model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_activation(model, activation_dic, activation_layer):\n",
    "    model.avgpool.register_forward_hook(save_activation(activation_dic, activation_layer))\n",
    "\n",
    "def save_activation(activation_dic, activation_layer):\n",
    "    def hook(model, input, output):\n",
    "        activation_dic[activation_layer] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dic = {}\n",
    "model = resnet34(pretrained=True).eval().to(device)\n",
    "hook_activation(model, activation_dic, activation_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_tensor(image):\n",
    "    return tran_F.to_tensor(image).unsqueeze(0).to(device, dtype=torch.float)\n",
    "\n",
    "def get_activation(activation_dic, activation_layer):\n",
    "    act_vec = nn_F.normalize(activation_dic[activation_layer], p=2, dim=1)\n",
    "    return act_vec.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00054843], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(0, 255, (64, 48, 3))\n",
    "model(img_to_tensor(x))\n",
    "activation = get_activation(activation_dic, activation_layer)\n",
    "\n",
    "print(np.shape(activation.squeeze()))\n",
    "activation[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_images(path, model_out, model, activation_dic, activation_layer, resize=False):\n",
    "    # Extract vectors:\n",
    "    filenames = glob.glob(path + '/*.jpg')\n",
    "    vectors = np.zeros((len(filenames), model_out))\n",
    "    for idx, img_path in enumerate(tqdm(filenames)):\n",
    "        \n",
    "        # Load image:\n",
    "        if resize:\n",
    "            image = Image.open(img_path).convert('RGB').resize((128, 128))\n",
    "        else:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "        # Vectorize image:        \n",
    "        model(img_to_tensor(image))\n",
    "        vectors[idx, :] = get_activation(activation_dic, activation_layer)\n",
    "        \n",
    "    return vectors, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    '''\n",
    "    >> ' '.join(sorted(set(''.join(list(set(brands))))))\n",
    "    >> \"& ' + - 1 2 3 4 ? a b c d e f g h i j kl m n\n",
    "        o p q r s t u v w x y z \\udcbc \\udcc3 \\udcfc\"\n",
    "    '''\n",
    "    filename = name.split('/')[-1]\n",
    "    brand = filename.split('_')[0]\n",
    "    return brand.encode('ascii', 'replace').decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(vectors, filenames, path):\n",
    "    vectors_list = [v for v in vectors]\n",
    "    brands = [clean_name(n) for n in filenames]\n",
    "    logos_df = pd.DataFrame({'brand': brands, 'img_vec': vectors_list})\n",
    "    # Save data:\n",
    "    logos_df.to_pickle(path + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76017/76017 [10:00<00:00, 126.49it/s]\n"
     ]
    }
   ],
   "source": [
    "logos_vectors, logos_filenames = vectorize_images(\n",
    "    logos_path, model_out, model, activation_dic, activation_layer)\n",
    "save_df(logos_vectors, logos_filenames, logos_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process logos (128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76017/76017 [10:19<00:00, 122.66it/s]\n"
     ]
    }
   ],
   "source": [
    "logos_128_vectors, logos_128_filenames = vectorize_images(\n",
    "    logos_128_path, model_out, model, activation_dic, activation_layer, resize=True)\n",
    "save_df(logos_128_vectors, logos_128_filenames, logos_128_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:04<00:00, 74.69it/s] \n"
     ]
    }
   ],
   "source": [
    "exemplars_vectors, exemplars_filenames = vectorize_images(\n",
    "    exemplars_path, model_out, model, activation_dic, activation_layer)\n",
    "save_df(exemplars_vectors, exemplars_filenames, exemplars_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process exemplars (128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:06<00:00, 57.68it/s]\n"
     ]
    }
   ],
   "source": [
    "exemplars_128_vectors, exemplars_128_filenames = vectorize_images(\n",
    "    exemplars_128_path, model_out, model, activation_dic, activation_layer, resize=True)\n",
    "save_df(exemplars_128_vectors, exemplars_128_filenames, exemplars_128_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
